{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea14a851",
   "metadata": {},
   "source": [
    "# Video Semantic Search - Production Version\n",
    "\n",
    "GPU-accelerated semantic search for YouTube videos using Whisper + FAISS.\n",
    "\n",
    "**Tech Stack:** Whisper (GPU), SentenceTransformers (CPU), FAISS vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f3f70",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install -q transformers accelerate\n",
    "!pip install -q yt-dlp librosa soundfile\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q faiss-cpu\n",
    "!pip install -q static-ffmpeg\n",
    "\n",
    "# Configure FFmpeg\n",
    "import os\n",
    "try:\n",
    "    import static_ffmpeg\n",
    "    static_ffmpeg.add_paths()\n",
    "    print(\"FFmpeg configured\")\n",
    "except:\n",
    "    print(\"FFmpeg auto-config failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a03e6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import faiss\n",
    "import yt_dlp\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a59ee",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device and models\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_SIZE = \"openai/whisper-base\"\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Directories\n",
    "FAISS_INDEX_DIR = \"faiss_index\"\n",
    "AUDIO_DIR = \"audio_cache\"\n",
    "os.makedirs(FAISS_INDEX_DIR, exist_ok=True)\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "\n",
    "# Search parameters\n",
    "TOP_K_RESULTS = 5\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Whisper Model: {MODEL_SIZE}\")\n",
    "print(f\"Embedding Model: {EMBEDDING_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff5b2b",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55638f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper (GPU)\n",
    "print(\"Loading Whisper model...\")\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_SIZE)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_SIZE).to(DEVICE)\n",
    "\n",
    "# Print model info\n",
    "if DEVICE == \"cuda\":\n",
    "    param_count = sum(p.numel() for p in model.parameters())\n",
    "    gpu_memory = torch.cuda.memory_allocated() / (1024**3)\n",
    "    print(f\"Model loaded: {param_count/1e6:.1f}M parameters\")\n",
    "    print(f\"GPU memory: {gpu_memory:.2f}GB\")\n",
    "else:\n",
    "    print(\"Model loaded (CPU mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395dfcc",
   "metadata": {},
   "source": [
    "## Transcription Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52591df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path: str, chunk_duration: int = 30) -> Tuple[str, List[Dict]]:\n",
    "    \"\"\"Transcribe audio file using Whisper.\"\"\"\n",
    "    \n",
    "    # Load audio\n",
    "    audio, sr = librosa.load(audio_path, sr=16000)\n",
    "    total_duration = len(audio) / sr\n",
    "    print(f\"Audio loaded: {total_duration:.1f} seconds\")\n",
    "    \n",
    "    # Process in chunks\n",
    "    chunk_size = chunk_duration * sr\n",
    "    all_text = []\n",
    "    \n",
    "    for i in range(0, len(audio), chunk_size):\n",
    "        chunk_audio = audio[i:i+chunk_size]\n",
    "        \n",
    "        # Convert to input features\n",
    "        input_features = processor(\n",
    "            chunk_audio, sampling_rate=16000, return_tensors=\"pt\"\n",
    "        ).input_features.to(DEVICE)\n",
    "        \n",
    "        # Generate transcription\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                language=\"en\",\n",
    "                max_length=448\n",
    "            )\n",
    "        \n",
    "        # Decode\n",
    "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        all_text.append(transcription)\n",
    "        \n",
    "        # Cleanup\n",
    "        del input_features, predicted_ids\n",
    "        if DEVICE == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    full_text = \" \".join(all_text)\n",
    "    \n",
    "    # Create time-based chunks for indexing\n",
    "    chunks = []\n",
    "    words = full_text.split()\n",
    "    if len(words) == 0:\n",
    "        return full_text, []\n",
    "    \n",
    "    words_per_second = len(words) / total_duration if total_duration > 0 else 1\n",
    "    words_per_chunk = int(words_per_second * chunk_duration)\n",
    "    \n",
    "    for i in range(0, len(words), max(1, words_per_chunk)):\n",
    "        chunk_words = words[i:i+words_per_chunk]\n",
    "        start_time = i / words_per_second if words_per_second > 0 else 0\n",
    "        end_time = min((i + len(chunk_words)) / words_per_second, total_duration)\n",
    "        \n",
    "        chunks.append({\n",
    "            'start': start_time,\n",
    "            'end': end_time,\n",
    "            'text': ' '.join(chunk_words)\n",
    "        })\n",
    "    \n",
    "    print(f\"Transcription complete: {len(chunks)} chunks\")\n",
    "    return full_text, chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c4b13c",
   "metadata": {},
   "source": [
    "## FAISS Index Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model (CPU to avoid GPU conflicts)\n",
    "print(\"Loading embedding model...\")\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device='cpu')\n",
    "dimension = embedding_model.get_sentence_embedding_dimension()\n",
    "print(f\"Embedding dimension: {dimension}\")\n",
    "\n",
    "# Initialize or load FAISS index\n",
    "index_path = os.path.join(FAISS_INDEX_DIR, \"index.faiss\")\n",
    "metadata_path = os.path.join(FAISS_INDEX_DIR, \"metadata.pkl\")\n",
    "\n",
    "if os.path.exists(index_path) and os.path.exists(metadata_path):\n",
    "    print(\"Loading existing index...\")\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(metadata_path, 'rb') as f:\n",
    "        metadata_store = pickle.load(f)\n",
    "    print(f\"Index loaded: {index.ntotal} documents\")\n",
    "else:\n",
    "    print(\"Creating new index...\")\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    metadata_store = {\n",
    "        'documents': [],\n",
    "        'metadatas': [],\n",
    "        'ids': []\n",
    "    }\n",
    "    print(\"New index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc5bcc",
   "metadata": {},
   "source": [
    "## YouTube Download Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url: str) -> str:\n",
    "    \"\"\"Extract YouTube video ID from URL.\"\"\"\n",
    "    patterns = [\n",
    "        r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*',\n",
    "        r'(?:embed\\/)([0-9A-Za-z_-]{11})',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    raise ValueError(f\"Invalid YouTube URL: {url}\")\n",
    "\n",
    "\n",
    "def download_youtube_audio(youtube_url: str) -> Tuple[str, str]:\n",
    "    \"\"\"Download audio from YouTube video.\"\"\"\n",
    "    \n",
    "    video_id = extract_video_id(youtube_url)\n",
    "    print(f\"Video ID: {video_id}\")\n",
    "    \n",
    "    # Check if already downloaded\n",
    "    for ext in ['.wav', '.mp3', '.m4a']:\n",
    "        audio_path = os.path.join(AUDIO_DIR, f\"{video_id}{ext}\")\n",
    "        if os.path.exists(audio_path):\n",
    "            print(f\"Using cached audio: {audio_path}\")\n",
    "            return audio_path, video_id\n",
    "    \n",
    "    # Download\n",
    "    print(\"Downloading audio...\")\n",
    "    audio_path_template = os.path.join(AUDIO_DIR, f'{video_id}.%(ext)s')\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': audio_path_template,\n",
    "        'quiet': True,\n",
    "        'no_warnings': True,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'wav',\n",
    "        }],\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "    \n",
    "    # Find downloaded file\n",
    "    audio_files = glob.glob(os.path.join(AUDIO_DIR, f\"{video_id}.*\"))\n",
    "    if audio_files:\n",
    "        audio_path = audio_files[0]\n",
    "        print(f\"Downloaded: {audio_path}\")\n",
    "        return audio_path, video_id\n",
    "    \n",
    "    raise Exception(\"Download failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4af9f7",
   "metadata": {},
   "source": [
    "## Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_video(youtube_url: str):\n",
    "    \"\"\"Complete ingestion pipeline: download -> transcribe -> embed -> index.\"\"\"\n",
    "    \n",
    "    global index, metadata_store\n",
    "    \n",
    "    print(f\"\\nIngesting: {youtube_url}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Download\n",
    "    audio_path, video_id = download_youtube_audio(youtube_url)\n",
    "    \n",
    "    # Transcribe\n",
    "    full_text, chunks = transcribe_audio(audio_path)\n",
    "    \n",
    "    if len(chunks) == 0:\n",
    "        print(\"No transcription generated\")\n",
    "        return\n",
    "    \n",
    "    # Prepare for indexing\n",
    "    documents = [chunk['text'] for chunk in chunks]\n",
    "    metadatas = [\n",
    "        {\n",
    "            'video_id': video_id,\n",
    "            'start_time': chunk['start'],\n",
    "            'end_time': chunk['end'],\n",
    "            'youtube_url': youtube_url\n",
    "        }\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    ids = [f\"{video_id}_chunk_{i}\" for i in range(len(chunks))]\n",
    "    \n",
    "    # Generate embeddings\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = embedding_model.encode(documents, show_progress_bar=False)\n",
    "    embeddings_np = np.array(embeddings).astype('float32')\n",
    "    \n",
    "    # Add to FAISS\n",
    "    index.add(embeddings_np)\n",
    "    metadata_store['documents'].extend(documents)\n",
    "    metadata_store['metadatas'].extend(metadatas)\n",
    "    metadata_store['ids'].extend(ids)\n",
    "    \n",
    "    # Save\n",
    "    faiss.write_index(index, index_path)\n",
    "    with open(metadata_path, 'wb') as f:\n",
    "        pickle.dump(metadata_store, f)\n",
    "    \n",
    "    print(f\"\\nIngestion complete!\")\n",
    "    print(f\"Total documents in index: {index.ntotal}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return video_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04c625",
   "metadata": {},
   "source": [
    "## Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, n_results: int = TOP_K_RESULTS):\n",
    "    \"\"\"Search for relevant video segments.\"\"\"\n",
    "    \n",
    "    if index.ntotal == 0:\n",
    "        print(\"Index is empty. Ingest videos first.\")\n",
    "        return []\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding_np = np.array(query_embedding).astype('float32')\n",
    "    \n",
    "    # Search\n",
    "    n_results = min(n_results, index.ntotal)\n",
    "    distances, indices = index.search(query_embedding_np, n_results)\n",
    "    \n",
    "    # Format results\n",
    "    results = []\n",
    "    for idx, distance in zip(indices[0], distances[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        \n",
    "        metadata = metadata_store['metadatas'][idx]\n",
    "        results.append({\n",
    "            'text': metadata_store['documents'][idx],\n",
    "            'start_time': metadata['start_time'],\n",
    "            'end_time': metadata['end_time'],\n",
    "            'video_id': metadata['video_id'],\n",
    "            'youtube_url': metadata['youtube_url'],\n",
    "            'confidence': max(0, 1 - (distance / 10)),\n",
    "            'distance': float(distance)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def format_time(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to timestamp.\"\"\"\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    if h > 0:\n",
    "        return f\"{h}:{m:02d}:{s:02d}\"\n",
    "    return f\"{m}:{s:02d}\"\n",
    "\n",
    "\n",
    "def print_results(results: List[Dict]):\n",
    "    \"\"\"Print search results.\"\"\"\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(results)} results:\\n\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        timestamp = format_time(result['start_time'])\n",
    "        confidence = result['confidence'] * 100\n",
    "        \n",
    "        print(f\"\\n[{i}] {timestamp} | Confidence: {confidence:.1f}%\")\n",
    "        print(f\"Video: {result['video_id']}\")\n",
    "        print(f\"Text: {result['text'][:200]}...\")\n",
    "        print(f\"URL: {result['youtube_url']}&t={int(result['start_time'])}s\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47de37",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest a video\n",
    "YOUTUBE_URL = \"https://www.youtube.com/watch?v=x7X9w_GIm1s\"\n",
    "current_video_id = ingest_video(YOUTUBE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0783c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search\n",
    "query = \"Where does he talk about numpy?\"\n",
    "results = search(query, n_results=5)\n",
    "print_results(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
